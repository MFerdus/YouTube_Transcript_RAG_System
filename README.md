
---

# ğŸ“š Retrieval-Augmented Generation (RAG) from YouTube Transcripts

This project implements an **end-to-end Retrieval-Augmented Generation (RAG) pipeline** that extracts knowledge from a YouTube video transcript and answers user questions **strictly grounded in the video content** using vector search and a large language model. 

---

## ğŸš€ Project Overview

The system follows the standard **RAG architecture**:

1. **Document Ingestion** â€“ Fetch YouTube video transcripts
2. **Chunking** â€“ Split long transcripts into manageable text chunks
3. **Embedding & Indexing** â€“ Convert chunks into vector embeddings and store them in FAISS
4. **Retrieval** â€“ Retrieve the most relevant transcript chunks for a user query
5. **Augmentation** â€“ Inject retrieved context into a controlled prompt
6. **Generation** â€“ Generate answers using an LLM constrained to retrieved context

This approach **reduces hallucinations** and ensures responses are **context-faithful**.

---

## ğŸ§  Architecture Flow

```
YouTube Video
     â†“
Transcript Extraction
     â†“
Text Chunking
     â†“
Vector Embeddings (OpenAI)
     â†“
FAISS Vector Store
     â†“
Similarity Search (Top-K)
     â†“
Prompt Augmentation
     â†“
LLM Answer Generation
```

---

## ğŸ§© Key Components

### 1ï¸âƒ£ Transcript Ingestion

* Uses `youtube-transcript-api` to fetch captions by **video ID**
* Supports English transcripts
* Gracefully handles videos with disabled captions 

---

### 2ï¸âƒ£ Text Chunking

* Applies `RecursiveCharacterTextSplitter`
* Configuration:

  * `chunk_size = 1000`
  * `chunk_overlap = 200`
* Ensures semantic continuity across chunks

---

### 3ï¸âƒ£ Embedding & Vector Storage

* Generates embeddings using **OpenAI embedding models**
* Stores embeddings in a **FAISS vector database**
* Enables fast semantic similarity search at scale 

---

### 4ï¸âƒ£ Retrieval

* Converts FAISS index into a retriever
* Uses **cosine similarity**
* Retrieves top-K most relevant chunks (`k = 4`) per query

---

### 5ï¸âƒ£ Prompt Augmentation

* Custom prompt template enforces **strict grounding**
* The model is instructed to:

  * Answer **only from retrieved transcript content**
  * Say *â€œI donâ€™t knowâ€* if information is missing

This ensures factual reliability and transparency.

---

### 6ï¸âƒ£ Answer Generation

* Uses an OpenAI chat model with **low temperature**
* Produces concise, context-aware answers
* Prevents hallucination outside retrieved evidence

---

### 7ï¸âƒ£ LangChain Pipeline (Composable Chains)

* Implements:

  * `RunnableParallel`
  * `RunnablePassthrough`
  * `RunnableLambda`
* Builds a reusable RAG chain supporting:

  * Direct Q&A
  * Video summarization
  * Named entity queries (e.g., â€œWho is Demis?â€)

---

## ğŸ› ï¸ Tech Stack

* **Python**
* **LangChain**
* **FAISS**
* **OpenAI Embeddings & Chat Models**
* **YouTube Transcript API**
* **tiktoken**
* **dotenv**

---

## â–¶ï¸ How to Run

```bash
pip install youtube-transcript-api langchain-community langchain-openai \
           faiss-cpu tiktoken python-dotenv
```

Set your API key:

```bash
export OPENAI_API_KEY="your_api_key"
```

Run the script:

```bash
python RAG.py
```

---


## ğŸ” Design Strengths

* Retrieval-grounded answers
* Reduced hallucination risk
* Modular, extensible RAG pipeline
* Production-ready architecture pattern

---



